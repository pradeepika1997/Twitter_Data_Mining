at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:1017)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:324)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:64)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:974)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:157)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:64)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:64)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:991)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:10 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@27261190: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:1017)
	at $line3.$read$$iwC$$iwC.<init>(<console>:9)
	at $line3.$read$$iwC.<init>(<console>:18)
	at $line3.$read.<init>(<console>:20)
	at $line3.$read$.<init>(<console>:24)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.<init>(<console>:7)
	at $line3.$eval$.<clinit>(<console>)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
	at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:324)
	at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:64)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:974)
	at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:157)
	at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:64)
	at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
	at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:64)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:991)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:43:10 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:43:10 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
	19/02/21 21:43:10 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:43:10 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4046
	19/02/21 21:43:10 INFO util.Utils: Successfully started service 'SparkUI' on port 4046.
	19/02/21 21:43:10 INFO ui.SparkUI: Started SparkUI at http://iop-bi-master.imdemocloud.com:4046
	19/02/21 21:43:10 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
	19/02/21 21:43:10 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
	19/02/21 21:43:10 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
	19/02/21 21:43:10 INFO executor.Executor: Starting executor ID driver on host localhost
	19/02/21 21:43:10 INFO executor.Executor: Using REPL class URI: http://108.168.178.78:28328
									19/02/21 21:43:11 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 8527.
																19/02/21 21:43:11 INFO netty.NettyBlockTransferService: Server created on 8527
	19/02/21 21:43:11 INFO storage.BlockManagerMaster: Trying to register BlockManager
									19/02/21 21:43:11 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:8527 with 265.1 MB RAM, BlockManagerId(driver, localhost, 8527)
																19/02/21 21:43:11 INFO storage.BlockManagerMaster: Registered BlockManager
																	    19/02/21 21:43:12 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
																		   19/02/21 21:43:12 INFO scheduler.EventLoggingListener: Logging events to hdfs://iop-bi-master.imdemocloud.com:8020/iop/apps/4.1.0.0/spark/logs/history-server/local-1550806990913
																			  19/02/21 21:43:12 INFO repl.SparkILoop: Created spark context..
																				 Spark context available as sc.
																					19/02/21 21:43:12 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
																					       19/02/21 21:43:13 INFO hive.HiveContext: Initializing execution hive, version 0.13.1
																					       19/02/21 21:43:13 INFO hive.metastore: Trying to connect to metastore with URI thrift://iop-bi-master.imdemocloud.com:9083
																					       19/02/21 21:43:13 INFO hive.metastore: Connected to metastore.
																					       19/02/21 21:43:13 INFO session.SessionState: No Tez session required at this point. hive.execution.engine=mr.
																					       19/02/21 21:43:13 INFO repl.SparkILoop: Created sql context (with Hive support)..
																					       SQL context available as sqlContext.

																					       scala> import org.apache.spark.SparkContext
																					       import org.apache.spark.SparkContext

																					       scala> import org.apache.spark.SparkContext._
																					       import org.apache.spark.SparkContext._

																					       scala> import org.apache.spark._
																					       import org.apache.spark._

																					       scala> val sc = new SparkContext( "local", "Word Count", "/usr/local/spark", Nil, Map(), Map())
																					       19/02/21 21:43:59 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
																					       19/02/21 21:43:59 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
																					       19/02/21 21:43:59 INFO spark.SparkContext: Running Spark version 1.4.1
																					       19/02/21 21:43:59 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
																					       19/02/21 21:43:59 INFO spark.SecurityManager: Changing view acls to: sindhusha55
																					       19/02/21 21:43:59 INFO spark.SecurityManager: Changing modify acls to: sindhusha55
																					       19/02/21 21:43:59 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sindhusha55); users with modify permissions: Set(sindhusha55)
																					       19/02/21 21:43:59 INFO slf4j.Slf4jLogger: Slf4jLogger started
																					       19/02/21 21:43:59 INFO Remoting: Starting remoting
																					       19/02/21 21:43:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:24337]
																					       19/02/21 21:43:59 INFO util.Utils: Successfully started service 'sparkDriver' on port 24337.
																					       19/02/21 21:43:59 INFO spark.SparkEnv: Registering MapOutputTracker
																					       19/02/21 21:43:59 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
																					       19/02/21 21:43:59 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
																					       19/02/21 21:43:59 INFO spark.SparkEnv: Registering BlockManagerMaster
																					       19/02/21 21:43:59 INFO storage.DiskBlockManager: Created local directory at /tmp/spark-132db49b-7d25-4be1-8a54-55b976b3f038/blockmgr-e4ec7734-2c3d-4636-8b71-6e01ca6e6fbe
																					       19/02/21 21:43:59 INFO storage.MemoryStore: MemoryStore started with capacity 246.0 MB
																					       19/02/21 21:43:59 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-132db49b-7d25-4be1-8a54-55b976b3f038/httpd-3248a731-d4fc-496f-a720-0f4ae2dc2bed
																					       19/02/21 21:43:59 INFO spark.HttpServer: Starting HTTP Server
																					       19/02/21 21:43:59 INFO server.Server: jetty-8.y.z-SNAPSHOT
																					       19/02/21 21:43:59 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:8038
																					       19/02/21 21:43:59 INFO util.Utils: Successfully started service 'HTTP file server' on port 8038.
																					       19/02/21 21:43:59 INFO spark.SparkEnv: Registering OutputCommitCoordinator
																					       19/02/21 21:43:59 INFO server.Server: jetty-8.y.z-SNAPSHOT
																					       19/02/21 21:43:59 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:59 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@6f18445b: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:43:59 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	19/02/21 21:43:59 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:43:59 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:59 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@18372705: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:43:59 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
	19/02/21 21:43:59 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:43:59 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:59 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@51a8aed8: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:43:59 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:44:00 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
	19/02/21 21:44:00 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@56114349: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:44:00 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
	19/02/21 21:44:00 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@78907a46: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:44:00 WARN util.Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
	19/02/21 21:44:00 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4045: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@4f50e974: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:44:00 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
	19/02/21 21:44:00 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4046: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 WARN component.AbstractLifeCycle: FAILED org.spark-project.jetty.server.Server@13e12ab6: java.net.BindException: Address already in use
	java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.Net.bind(Net.java:429)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $line24.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $line24.$read$$iwC$$iwC$$iwC.<init>(<console>:47)
	at $line24.$read$$iwC$$iwC.<init>(<console>:49)
	at $line24.$read$$iwC.<init>(<console>:51)
	at $line24.$read.<init>(<console>:53)
	at $line24.$read$.<init>(<console>:57)
	at $line24.$read$.<clinit>(<console>)
	at $line24.$eval$.<init>(<console>:7)
	at $line24.$eval$.<clinit>(<console>)
	at $line24.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:44:00 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:44:00 WARN util.Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
	19/02/21 21:44:00 INFO server.Server: jetty-8.y.z-SNAPSHOT
	19/02/21 21:44:00 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4047
	19/02/21 21:44:00 INFO util.Utils: Successfully started service 'SparkUI' on port 4047.
	19/02/21 21:44:00 INFO ui.SparkUI: Started SparkUI at http://iop-bi-master.imdemocloud.com:4047
	19/02/21 21:44:00 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
	19/02/21 21:44:00 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
	19/02/21 21:44:00 WARN spark.SparkConf: The configuration key 'spark.yarn.applicationMaster.waitTries' has been deprecated as of Spark 1.3 and and may be removed in the future. Please use the new key 'spark.yarn.am.waitTime' instead.
	19/02/21 21:44:00 INFO executor.Executor: Starting executor ID driver on host localhost
	19/02/21 21:44:00 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 1057.
	19/02/21 21:44:00 INFO netty.NettyBlockTransferService: Server created on 1057
	19/02/21 21:44:00 INFO storage.BlockManagerMaster: Trying to register BlockManager
19/02/21 21:44:00 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:1057 with 246.0 MB RAM, BlockManagerId(driver, localhost, 1057)
	19/02/21 21:44:00 INFO storage.BlockManagerMaster: Registered BlockManager
	19/02/21 21:44:00 INFO scheduler.EventLoggingListener: Logging events to hdfs://iop-bi-master.imdemocloud.com:8020/iop/apps/4.1.0.0/spark/logs/history-server/local-1550807040293
	org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
	org.apache.spark.SparkContext.<init>(SparkContext.scala:81)
	org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:1017)
	$iwC$$iwC.<init>(<console>:9)
	$iwC.<init>(<console>:18)
	<init>(<console>:20)
	.<init>(<console>:24)
	.<clinit>(<console>)
	.<init>(<console>:7)
	.<clinit>(<console>)
	$print(<console>)
	sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	java.lang.reflect.Method.invoke(Method.java:497)
	org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2085)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2067)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2153)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2025)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:155)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $iwC$$iwC$$iwC.<init>(<console>:47)
	at $iwC$$iwC.<init>(<console>:49)
	at $iwC.<init>(<console>:51)
	at <init>(<console>:53)
	at .<init>(<console>:57)
	at .<clinit>(<console>)
	at .<init>(<console>:7)
	at .<clinit>(<console>)
	at $print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:665)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:170)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:193)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:112)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)


	scala>       val input = sc.textFile("/user/sindhusha55/WordCount/input/sample.txt")
	19/02/21 21:44:29 INFO storage.MemoryStore: ensureFreeSpace(294920) called with curMem=0, maxMem=257918238
19/02/21 21:44:29 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 288.0 KB, free 245.7 MB)
	19/02/21 21:44:29 INFO storage.MemoryStore: ensureFreeSpace(25724) called with curMem=294920, maxMem=257918238
	19/02/21 21:44:29 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.1 KB, free 245.7 MB)
19/02/21 21:44:29 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:1057 (size: 25.1 KB, free: 245.9 MB)
	19/02/21 21:44:29 INFO spark.SparkContext: Created broadcast 0 from textFile at <console>:28
	input: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at <console>:28

	scala> val count = input.flatMap(line => line.split(" ")).map(word => (word, 1)).reduceByKey(_ + _)
	19/02/21 21:44:44 INFO mapred.FileInputFormat: Total input paths to process : 1
	count: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at <console>:30

scala> count.foreach(println)
	19/02/21 21:44:53 INFO spark.SparkContext: Starting job: foreach at <console>:33
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: Registering RDD 3 (map at <console>:30)
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: Got job 0 (foreach at <console>:33) with 2 output partitions (allowLocal=false)
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 1(foreach at <console>:33)
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
19/02/21 21:44:53 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at <console>:30), which has no missing parents
	19/02/21 21:44:53 INFO storage.MemoryStore: ensureFreeSpace(4184) called with curMem=320644, maxMem=257918238
19/02/21 21:44:53 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 245.7 MB)
	19/02/21 21:44:53 INFO storage.MemoryStore: ensureFreeSpace(2308) called with curMem=324828, maxMem=257918238
	19/02/21 21:44:53 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 245.7 MB)
19/02/21 21:44:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:1057 (size: 2.3 KB, free: 245.9 MB)
	19/02/21 21:44:53 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:874
19/02/21 21:44:53 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at <console>:30)
	19/02/21 21:44:53 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
	19/02/21 21:44:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, ANY, 1447 bytes)
	19/02/21 21:44:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, ANY, 1447 bytes)
	19/02/21 21:44:53 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
19/02/21 21:44:53 INFO executor.Executor: Running task 1.0 in stage 0.0 (TID 1)
	19/02/21 21:44:53 INFO rdd.HadoopRDD: Input split: hdfs://iop-bi-master.imdemocloud.com:8020/user/sindhusha55/WordCount/input/sample.txt:0+10
	19/02/21 21:44:53 INFO rdd.HadoopRDD: Input split: hdfs://iop-bi-master.imdemocloud.com:8020/user/sindhusha55/WordCount/input/sample.txt:10+11
	19/02/21 21:44:53 INFO executor.Executor: Finished task 1.0 in stage 0.0 (TID 1). 2002 bytes result sent to driver
	19/02/21 21:44:53 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2002 bytes result sent to driver
	19/02/21 21:44:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 141 ms on localhost (1/2)
19/02/21 21:44:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 129 ms on localhost (2/2)
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (map at <console>:30) finished in 0.158 s
	19/02/21 21:44:53 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: looking for newly runnable stages
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: running: Set()
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: failed: Set()
19/02/21 21:44:53 INFO scheduler.DAGScheduler: Missing parents for ResultStage 1: List()
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at <console>:30), which is now runnable
	19/02/21 21:44:53 INFO storage.MemoryStore: ensureFreeSpace(2272) called with curMem=327136, maxMem=257918238
19/02/21 21:44:53 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.2 KB, free 245.7 MB)
	19/02/21 21:44:53 INFO storage.MemoryStore: ensureFreeSpace(1354) called with curMem=329408, maxMem=257918238
	19/02/21 21:44:53 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1354.0 B, free 245.7 MB)
19/02/21 21:44:53 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:1057 (size: 1354.0 B, free: 245.9 MB)
	19/02/21 21:44:53 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:874
19/02/21 21:44:53 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at <console>:30)
	19/02/21 21:44:53 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
	19/02/21 21:44:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1165 bytes)
	19/02/21 21:44:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 1165 bytes)
	19/02/21 21:44:53 INFO executor.Executor: Running task 1.0 in stage 1.0 (TID 3)
19/02/21 21:44:53 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 2)
	19/02/21 21:44:53 INFO spark.MapOutputTrackerMaster: Don't have map outputs for shuffle 0, fetching them
	19/02/21 21:44:53 INFO spark.MapOutputTrackerMaster: Don't have map outputs for shuffle 0, fetching them
	19/02/21 21:44:53 INFO spark.MapOutputTrackerMaster: Doing the fetch; tracker endpoint = AkkaRpcEndpointRef(Actor[akka://sparkDriver/user/MapOutputTracker#1769621618])
	19/02/21 21:44:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to localhost:24337
	19/02/21 21:44:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 82 bytes
	19/02/21 21:44:53 INFO spark.MapOutputTrackerMaster: Got the output locations
	19/02/21 21:44:53 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
	19/02/21 21:44:53 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
	19/02/21 21:44:53 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
	19/02/21 21:44:53 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
	19/02/21 21:44:53 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 2). 886 bytes result sent to driver
	19/02/21 21:44:53 INFO executor.Executor: Finished task 1.0 in stage 1.0 (TID 3). 886 bytes result sent to driver
	19/02/21 21:44:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 46 ms on localhost (1/2)
19/02/21 21:44:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 49 ms on localhost (2/2)
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: ResultStage 1 (foreach at <console>:33) finished in 0.046 s
	19/02/21 21:44:53 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
	19/02/21 21:44:53 INFO scheduler.DAGScheduler: Job 0 finished: foreach at <console>:33, took 0.355954 s

	scala> count.collect().foreach(println)
	19/02/21 21:46:15 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on localhost:1057 in memory (size: 1354.0 B, free: 245.9 MB)
19/02/21 21:46:15 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on localhost:1057 in memory (size: 2.3 KB, free: 245.9 MB)
	19/02/21 21:46:15 INFO spark.SparkContext: Starting job: collect at <console>:33
	19/02/21 21:46:15 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes
	19/02/21 21:46:15 INFO scheduler.DAGScheduler: Got job 1 (collect at <console>:33) with 2 output partitions (allowLocal=false)
	19/02/21 21:46:15 INFO scheduler.DAGScheduler: Final stage: ResultStage 3(collect at <console>:33)
	19/02/21 21:46:15 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
19/02/21 21:46:15 INFO scheduler.DAGScheduler: Missing parents: List()
	19/02/21 21:46:15 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (ShuffledRDD[4] at reduceByKey at <console>:30), which has no missing parents
	19/02/21 21:46:15 INFO storage.MemoryStore: ensureFreeSpace(2312) called with curMem=320644, maxMem=257918238
19/02/21 21:46:15 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.3 KB, free 245.7 MB)
	19/02/21 21:46:15 INFO storage.MemoryStore: ensureFreeSpace(1377) called with curMem=322956, maxMem=257918238
	19/02/21 21:46:15 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1377.0 B, free 245.7 MB)
19/02/21 21:46:15 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:1057 (size: 1377.0 B, free: 245.9 MB)
	19/02/21 21:46:15 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:874
19/02/21 21:46:15 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (ShuffledRDD[4] at reduceByKey at <console>:30)
	19/02/21 21:46:15 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
	19/02/21 21:46:15 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, PROCESS_LOCAL, 1165 bytes)
	19/02/21 21:46:15 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5, localhost, PROCESS_LOCAL, 1165 bytes)
	19/02/21 21:46:15 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 4)
19/02/21 21:46:15 INFO executor.Executor: Running task 1.0 in stage 3.0 (TID 5)
	19/02/21 21:46:15 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
	19/02/21 21:46:15 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
	19/02/21 21:46:15 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	19/02/21 21:46:15 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	19/02/21 21:46:15 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 4). 882 bytes result sent to driver
	19/02/21 21:46:15 INFO executor.Executor: Finished task 1.0 in stage 3.0 (TID 5). 882 bytes result sent to driver
	19/02/21 21:46:15 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 11 ms on localhost (1/2)
19/02/21 21:46:15 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 11 ms on localhost (2/2)
	19/02/21 21:46:15 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
	19/02/21 21:46:15 INFO scheduler.DAGScheduler: ResultStage 3 (collect at <console>:33) finished in 0.012 s
	19/02/21 21:46:15 INFO scheduler.DAGScheduler: Job 1 finished: collect at <console>:33, took 0.024247 s

	scala> count.saveAsTextFile("/user/sindhusha55/WordCount/output/sample")
	19/02/21 21:47:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
	19/02/21 21:47:13 INFO spark.SparkContext: Starting job: saveAsTextFile at <console>:33
	19/02/21 21:47:13 INFO scheduler.DAGScheduler: Got job 2 (saveAsTextFile at <console>:33) with 2 output partitions (allowLocal=false)
	19/02/21 21:47:13 INFO scheduler.DAGScheduler: Final stage: ResultStage 5(saveAsTextFile at <console>:33)
	19/02/21 21:47:13 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
19/02/21 21:47:13 INFO scheduler.DAGScheduler: Missing parents: List()
	19/02/21 21:47:13 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[5] at saveAsTextFile at <console>:33), which has no missing parents
	19/02/21 21:47:13 INFO storage.MemoryStore: ensureFreeSpace(154520) called with curMem=324333, maxMem=257918238
19/02/21 21:47:13 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 150.9 KB, free 245.5 MB)
	19/02/21 21:47:13 INFO storage.MemoryStore: ensureFreeSpace(54636) called with curMem=478853, maxMem=257918238
	19/02/21 21:47:13 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 53.4 KB, free 245.5 MB)
19/02/21 21:47:13 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:1057 (size: 53.4 KB, free: 245.9 MB)
	19/02/21 21:47:13 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:874
19/02/21 21:47:13 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[5] at saveAsTextFile at <console>:33)
	19/02/21 21:47:13 INFO scheduler.TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
	19/02/21 21:47:13 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, PROCESS_LOCAL, 1165 bytes)
	19/02/21 21:47:13 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7, localhost, PROCESS_LOCAL, 1165 bytes)
	19/02/21 21:47:13 INFO executor.Executor: Running task 1.0 in stage 5.0 (TID 7)
19/02/21 21:47:13 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 6)
	19/02/21 21:47:13 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
	19/02/21 21:47:13 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
	19/02/21 21:47:13 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	19/02/21 21:47:13 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
	19/02/21 21:47:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
	19/02/21 21:47:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
	19/02/21 21:47:13 INFO output.FileOutputCommitter: Saved output of task 'attempt_201902212147_0005_m_000001_7' to hdfs://iop-bi-master.imdemocloud.com:8020/user/sindhusha55/WordCount/output/sample/_temporary/0/task_201902212147_0005_m_000001
	19/02/21 21:47:13 INFO output.FileOutputCommitter: Saved output of task 'attempt_201902212147_0005_m_000000_6' to hdfs://iop-bi-master.imdemocloud.com:8020/user/sindhusha55/WordCount/output/sample/_temporary/0/task_201902212147_0005_m_000000
	19/02/21 21:47:13 INFO mapred.SparkHadoopMapRedUtil: attempt_201902212147_0005_m_000000_6: Committed
	19/02/21 21:47:13 INFO mapred.SparkHadoopMapRedUtil: attempt_201902212147_0005_m_000001_7: Committed
	19/02/21 21:47:13 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 6). 1828 bytes result sent to driver
	19/02/21 21:47:13 INFO executor.Executor: Finished task 1.0 in stage 5.0 (TID 7). 1828 bytes result sent to driver
	19/02/21 21:47:13 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 163 ms on localhost (1/2)
19/02/21 21:47:13 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 163 ms on localhost (2/2)
	19/02/21 21:47:13 INFO scheduler.DAGScheduler: ResultStage 5 (saveAsTextFile at <console>:33) finished in 0.164 s
	19/02/21 21:47:13 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
	19/02/21 21:47:13 INFO scheduler.DAGScheduler: Job 2 finished: saveAsTextFile at <console>:33, took 0.306043 s

	scala> :q
	Stopping spark context.
	19/02/21 21:47:40 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on localhost:1057 in memory (size: 1377.0 B, free: 245.9 MB)
19/02/21 21:47:40 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on localhost:1057 in memory (size: 53.4 KB, free: 245.9 MB)
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:47:41 INFO ui.SparkUI: Stopped Spark web UI at http://iop-bi-master.imdemocloud.com:4046
	19/02/21 21:47:41 INFO scheduler.DAGScheduler: Stopping DAGScheduler
	19/02/21 21:47:41 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	19/02/21 21:47:41 INFO util.Utils: path = /tmp/spark-132db49b-7d25-4be1-8a54-55b976b3f038/blockmgr-1c1860db-63bd-4956-a369-daa4dc24c15f, already present as root for deletion.
	19/02/21 21:47:41 INFO storage.MemoryStore: MemoryStore cleared
	19/02/21 21:47:41 INFO storage.BlockManager: BlockManager stopped
	19/02/21 21:47:41 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
	19/02/21 21:47:41 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	19/02/21 21:47:41 INFO spark.SparkContext: Successfully stopped SparkContext
	19/02/21 21:47:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
	19/02/21 21:47:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
	19/02/21 21:47:41 INFO spark.SparkContext: Invoking stop() from shutdown hook
	19/02/21 21:47:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
	19/02/21 21:47:41 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
	19/02/21 21:47:41 INFO ui.SparkUI: Stopped Spark web UI at http://iop-bi-master.imdemocloud.com:4047
	19/02/21 21:47:41 INFO scheduler.DAGScheduler: Stopping DAGScheduler
	19/02/21 21:47:41 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
	19/02/21 21:47:41 INFO util.Utils: path = /tmp/spark-132db49b-7d25-4be1-8a54-55b976b3f038/blockmgr-e4ec7734-2c3d-4636-8b71-6e01ca6e6fbe, already present as root for deletion.
	19/02/21 21:47:41 INFO storage.MemoryStore: MemoryStore cleared
	19/02/21 21:47:41 INFO storage.BlockManager: BlockManager stopped
	19/02/21 21:47:41 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
	19/02/21 21:47:41 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
	19/02/21 21:47:41 INFO spark.SparkContext: Successfully stopped SparkContext
	19/02/21 21:47:41 INFO util.Utils: Shutdown hook called
	19/02/21 21:47:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
	19/02/21 21:47:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
	19/02/21 21:47:41 INFO util.Utils: Deleting directory /tmp/spark-b30d6439-4ac3-46ff-a4f8-8ea17df3367d
	19/02/21 21:47:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
	19/02/21 21:47:41 INFO util.Utils: Deleting directory /tmp/spark-13d34dc1-863f-42c8-a0a0-b337ba21d807
	19/02/21 21:47:41 INFO util.Utils: Deleting directory /tmp/spark-132db49b-7d25-4be1-8a54-55b976b3f038
	[sindhusha55@iop-bi-master hashtags.txt]$
	[sindhusha55@iop-bi-master hashtags.txt]$
	[sindhusha55@iop-bi-master hashtags.txt]$ hadoop fs -ls /user/sindhusha55/WordCount/output/sample
	Found 3 items
	-rw-rw----+  3 sindhusha55 sindhusha55          0 2019-02-21 21:47 /user/sindhusha55/WordCount/output/sample/_SUCCESS
	-rw-rw----+  3 sindhusha55 sindhusha55          0 2019-02-21 21:47 /user/sindhusha55/WordCount/output/sample/part-00000
	-rw-rw----+  3 sindhusha55 sindhusha55          0 2019-02-21 21:47 /user/sindhusha55/WordCount/output/sample/part-00001
